{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP.ipynb","provenance":[],"authorship_tag":"ABX9TyPwkhjD8enYdRr/pMCuKU7S"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JhEjxWzXqoxh","colab_type":"code","colab":{}},"source":["!pip uninstall pandas-profiling"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jaWkb__qpCa","colab_type":"code","colab":{}},"source":["!pip install pandas-profiling==2.7.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvB2V4eNtm0J","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","from torch import nn, from_numpy, optim\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","#pandas- librărie pentru lucrul cu fișierele\n","import pandas as pd\n","from pandas_profiling import ProfileReport\n","#folosim o functie din sklearn ce creaza seturi de date pentru antrenare si validare\n","from sklearn.model_selection import train_test_split\n","#Pentru normalizarea datelor folosim MinMaxScaler din sklearn\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIv31r8hqmSd","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.style.use(\"ggplot\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2yv_8Jhtunz","colab_type":"code","colab":{}},"source":["df=pd.read_csv(\"/content/winequality-red.csv\")\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRQ57CwTq7Xm","colab_type":"code","colab":{}},"source":["#Statisticile pot fi salvate În format html\n","prof=ProfileReport(df,minimal=True)\n","prof.to_file(output_file='/content/output-min.html')\n","prof"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VSlcE2SrMJa","colab_type":"code","colab":{}},"source":["#Selectăm datele de intrare in retea eliminand ultima coloană din csv\n","X = df.drop(\"quality\", axis=1)\n","#obținem etichetele pentru date salvand ultima coloana\n","y = df['quality']\n","#primim ca output seturile de date corespunzatoare.\n","#Test size ne spune cat de mare procentual sa avem setul de validare\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n","\n","sum(y_train), len(y_train), sum(y_test), len(y_test)\n","X_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x55LJABmvG4P","colab_type":"code","colab":{}},"source":["# Functia va translata fiecare feature in parte in intervalul (-1,1)\n","# Funcția practic relizează următoarele\n","# X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n","# X_scaled = X_std * (max - min) + min\n","\n","sc = MinMaxScaler((-1, 1))\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","X_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lI3yQ-m1uDFZ","colab_type":"code","colab":{}},"source":["#Dataset - o clasă din PyTorch foarte utilă gestionării seturilor de date\n","class Dataset(Dataset):\n","    \"\"\" Wine dataset.\"\"\"\n","    # Initialize your data, download, etc.\n","    def __init__(self, x, y):\n","        #Citim setul de date\n","        self.len = len(x)\n","\n","        self.x=torch.tensor(x).float()\n","        self.y=torch.tensor(y.values).long()\n","\n","    def __getitem__(self, index):\n","        return self.x[index], self.y[index]\n","\n","    def __len__(self):\n","        return self.len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ip-1FLaNvyqX","colab_type":"code","colab":{}},"source":["trainDataset=Dataset(X_train, y_train)\n","trainLoader=DataLoader(dataset=trainDataset,\n","                        batch_size=16,\n","                        shuffle=True,\n","                        num_workers=1)\n","\n","validationDataset=Dataset(X_test, y_test)\n","validationLoader=DataLoader(dataset=validationDataset,\n","                        batch_size=16,\n","                        shuffle=True,\n","                        num_workers=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k25wYk9IuDpo","colab_type":"code","colab":{}},"source":["class WineNN(nn.Module):    \n","    def __init__(self):\n","        super(WineNN, self).__init__()\n","\n","        #Sequential oferă o alternativă mai estetică a codului\n","        #Rețeaua noastră are 2 neuroni pentru output. \n","        #Unul va prezice probabilitatea pentru cazul afirmativ al bolii, iar celălalt va prezice probabilitatea cazului negativ al bolii.\n","        self.sequential= nn.Sequential(\n","            nn.Linear(11,50),\n","            nn.ReLU(),\n","            nn.Linear(50, 100),\n","            nn.ReLU(),\n","            nn.Linear(100, 30),\n","            nn.ReLU(),\n","            nn.Linear(30, 60),\n","            nn.ReLU(),\n","            nn.Linear(60, 2)\n","        )\n","\n","    def forward(self, x):\n","        return self.sequential(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BnJFBSf6uYl0","colab_type":"code","colab":{}},"source":["net = WineNN()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_RXBbZluYvt","colab_type":"code","colab":{}},"source":["# CrossEntropyLoss este folosit adeseori in problemele de clasificare\n","# Acesta este compus din functia SoftMax și NLLLoss\n","# Softmax - Mapează elementele din Tensor in intervalul [0,1] și face ca suma lor să fie 1. O functie foarte utilă atunci cand vrem sa calculam probabilitati dintr-un Tensor.\n","# NLLLoss - negative log likelihood loss, functie folosită adeseori in problemele de clasificare\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyiJ540kzsuO","colab_type":"code","colab":{}},"source":["# Colectăm loss-urile din antrenare pentru a le plota ulterior\n","train_losses = []\n","# Colectăm accuratetea pentru a o plota ulterior\n","accuracies=[]\n","# Colectăm loss-ul din validare pentru a o plota ulterior\n","test_losses=[]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOUwqevMwB2k","colab_type":"code","colab":{}},"source":["# Training loop\n","def train(epoch):\n","    # Setează câteva flaguri în rețeaua neurală. Specific activează Dropout-ul și BatchNormalization dacă este cazul.\n","    # În exemplul nostru are un rol pur demonstrativ, nefiind necesar.\n","    net.train()\n","    losses=[]\n","    for batch_idx, data in enumerate(trainLoader, 0):\n","      inputs, labels =data\n","      #Obținem predictii\n","      outputs = net(inputs)\n","      # Compute and print loss\n","      loss = criterion(outputs, labels)\n","\n","      losses.append(loss.item())\n","      # Zero gradients, perform a backward pass, and update the weights.\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      print(f\"[Train Epoch: {epoch}, Batch: {batch_idx+1}, Loss: {loss.item()}\")\n","    mean_loss=sum(losses)/len(losses)\n","    scheduler.step(mean_loss)\n","    train_losses.append(mean_loss)\n","    print(f\"[TRAIN] Epoch: {epoch} Loss:{mean_loss}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QqpBpxnZ0LlJ","colab_type":"code","colab":{}},"source":["def validation():\n","    #Pune pe off flagurile setate in model.train()\n","    #Din nou, în exemplul nostru e pur demonstrativ.\n","    net.eval()\n","\n","    test_loss=[]\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(validationLoader, 0):\n","          inputs, labels = data\n","\n","          output=net(inputs)\n","\n","          loss= criterion(output, labels)\n","          test_loss.append(loss.item())\n","\n","          #Obținem predictiile pentru fiecare linie din setul de validare.\n","          #Practic ne returnează rezultatul cu cea mai mare probabilitate pentru fiecare intrare din setul de validare \n","          pred = output.data.max(1, keepdim=True)[1]\n","\n","          #Verificăm câte predicții sunt corecte și le însumăm numărul pentru a afla totalul de predicții corecte\n","          correct += pred.eq(labels.data.view_as(pred)).sum()\n","          current_correct=pred.eq(labels.data.view_as(pred)).sum()          \n","          print(\"============\")\n","          print(f\"[Validation set] Batch index: {batch_idx+1} Batch loss: {loss.item()}, Accuracy: {100. * current_correct/len(inputs)}%\")\n","          print(\"============\")\n","        mean_loss=sum(test_loss)/len(test_loss)\n","        test_losses.append(mean_loss)\n","        accuracy = 100. * correct/len(validationLoader.dataset)\n","        print(f\"[Validation set] Loss: {mean_loss}, Accuracy: {accuracy}%\")\n","          \n","        accuracies.append(accuracy)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BseaHJhM0Qth","colab_type":"code","colab":{}},"source":["#după fiecare epocă de train() verificăm rezultatele pe setul de validare\n","for epoch in range(100):\n","  train(epoch)\n","  validation()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpBH9fqa0ZZx","colab_type":"code","colab":{}},"source":["# Printăm comparativ cu roșu loss-ul de pe setul de validare și cu albastru loss-ul de pe setul de validare.\n","plt.plot(train_losses, \"r-\", test_losses, \"b-\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Mu3DW4_0a7k","colab_type":"code","colab":{}},"source":["plt.plot(accuracies)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtGFDzxD0dpn","colab_type":"code","colab":{}},"source":["#Let's try and feed a single example in the neural network and see if it gets it right\n","def try_a_single_example_with_the_network(index_from_the_validation_set):\n","  with torch.no_grad():\n","    pred_test = net(validationDataset[index_from_the_validation_set][0].view(1, -1))\n","    _, preds_y = torch.max(pred_test, 1)\n","    return preds_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWBiNF6S0f9g","colab_type":"code","colab":{}},"source":["index_of_test=4\n","print(f\"Neural network response is: {try_a_single_example_with_the_network(index_of_test).item()}\")\n","print(f\"Actual response is: {validationDataset[index_of_test][1].view(-1).item()}\")"],"execution_count":0,"outputs":[]}]}