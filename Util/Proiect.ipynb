{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Proiect.ipynb","provenance":[],"authorship_tag":"ABX9TyM7tqmYfH+ajZGaAAj6Q8v+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SvB2V4eNtm0J","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","from torch import nn, from_numpy, optim\n","import numpy as np\n","#pandas- librărie pentru lucrul cu fișierele\n","import pandas as pd\n","import torch\n","import torch.nn as nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2yv_8Jhtunz","colab_type":"code","colab":{}},"source":["df=pd.read_csv(\"/content/winequality-red.csv\",header=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Xl0eENXuAlg","colab_type":"code","outputId":"5070683f-6a46-4677-ceb3-cc9e22a884c8","executionInfo":{"status":"ok","timestamp":1589829930434,"user_tz":-180,"elapsed":668,"user":{"displayName":"Roxi Yuki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgC8aSCDKocCI7M2lGd40bE5ixCY_LuPEcEDIAdjw=s64","userId":"15259967487885519795"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["df.values"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 7.4  ,  0.7  ,  0.   , ...,  0.56 ,  9.4  ,  0.   ],\n","       [ 7.8  ,  0.88 ,  0.   , ...,  0.68 ,  9.8  ,  0.   ],\n","       [ 7.8  ,  0.76 ,  0.04 , ...,  0.65 ,  9.8  ,  0.   ],\n","       ...,\n","       [ 6.3  ,  0.51 ,  0.13 , ...,  0.75 , 11.   ,  1.   ],\n","       [ 5.9  ,  0.645,  0.12 , ...,  0.71 , 10.2  ,  0.   ],\n","       [ 6.   ,  0.31 ,  0.47 , ...,  0.66 , 11.   ,  1.   ]])"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"lI3yQ-m1uDFZ","colab_type":"code","colab":{}},"source":["#Dataset - o clasă din PyTorch foarte utilă gestionării seturilor de date\n","class WineDataset(Dataset):\n","    \"\"\" Diabetes dataset.\"\"\"\n","    # Initialize your data, download, etc.\n","    def __init__(self):\n","        #Citim setul de date\n","        df=pd.read_csv(\"/content/winequality-red.csv\",header=None, dtype=np.float32)\n","        xy = torch.from_numpy(df.values)\n","        self.len = xy.shape[0]\n","        #Vom folosi ca input toate valorile mai puțin ultima coloană\n","        self.x_data = xy[:, 0:-1]\n","        #Vom folosi ca output ultima coloană\n","        self.y_data = xy[:, [-1]]\n","\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    def __len__(self):\n","        return self.len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ht-ytfdMuDWO","colab_type":"code","colab":{}},"source":["dataset = WineDataset()\n","#DataLoader - un utilitar ce ne ajută să împărțim setul de date pe batch-uri și astfel să facem antrenare în mod Mini-Batch\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=32,\n","                          shuffle=True,\n","                          num_workers=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9juhYwoOuDfp","colab_type":"code","outputId":"d5661c8a-97f1-42fe-d77a-e889a116d250","executionInfo":{"status":"ok","timestamp":1589829936350,"user_tz":-180,"elapsed":990,"user":{"displayName":"Roxi Yuki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgC8aSCDKocCI7M2lGd40bE5ixCY_LuPEcEDIAdjw=s64","userId":"15259967487885519795"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["dataset[0]"],"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 7.4000,  0.7000,  0.0000,  1.9000,  0.0760, 11.0000, 34.0000,  0.9978,\n","          3.5100,  0.5600,  9.4000]), tensor([0.]))"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"k25wYk9IuDpo","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","\n","    def __init__(self):\n","        \"\"\"\n","        In the constructor we instantiate two nn.Linear module\n","        \"\"\"\n","        super(Model, self).__init__()\n","        self.l1 = nn.Linear(11, 100)\n","        self.l2 = nn.Linear(100, 50)\n","        self.l3 = nn.Linear(50, 30)\n","        self.l4 = nn.Linear(30, 80)\n","        self.l5 = nn.Linear(80, 10)\n","        self.l6 = nn.Linear(10, 1)\n","\n","        self.sigmoid = nn.Sigmoid()\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        \"\"\"\n","        In the forward function we accept a Variable of input data and we must return\n","        a Variable of output data. We can use Modules defined in the constructor as\n","        well as arbitrary operators on Variables.\n","        \"\"\"\n","        out1 = self.relu(self.l1(x))\n","        out2 = self.relu(self.l2(out1))\n","        out3 = self.relu(self.l3(out2))\n","        out4 = self.relu(self.l4(out3))\n","        out5 = self.relu(self.l5(out4))\n","        y_pred = self.sigmoid(self.l6(out5))\n","        return y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BnJFBSf6uYl0","colab_type":"code","colab":{}},"source":["model=Model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_RXBbZluYvt","colab_type":"code","colab":{}},"source":["criterion = nn.BCELoss(reduction='sum')\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOUwqevMwB2k","colab_type":"code","colab":{}},"source":["# Training loop\n","for epoch in range(100):\n","  #Aplicăm modificarea de learning rate per epocă, deci va trebui să avem un istoric al loss-ului\n","  for i, data in enumerate(train_loader, 0):\n","      # get the inputs\n","      inputs, labels = data\n","\n","      # Forward pass: Compute predicted y by passing x to the model\n","      y_pred = model(inputs)\n","\n","      # Compute and print loss\n","      loss = criterion(y_pred, labels)\n","      print(f'Epoch {epoch + 1} | Batch: {i+1} | Loss: {loss.item():.4f}')\n","\n","      # Zero gradients, perform a backward pass, and update the weights.\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()"],"execution_count":0,"outputs":[]}]}